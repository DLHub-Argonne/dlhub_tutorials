{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DLHub: A Data and Learning Hub for Science\n",
    "\n",
    "DLHub is a self-service platform for publishing, applying, and creating machine learning (ML) models, including deep learning (DL) models, and associated data transformations. It is:\n",
    "\n",
    "1. A **model serving infrastructure**: Users can easily run or test models (and also other related services, such as data transformations) via simple Web calls.\n",
    "\n",
    "2. A **model registry**: Model developers can easily publish models, along with associated descriptive metadata and training data, so that they can then be discovered, cited, and reused by others.\n",
    "\n",
    "3. A **model development system**: Developers of new models can easily access the data and computing infrastructure needed to re-train models for new applications.\n",
    "\n",
    "DLHub benefits users in many ways. Data scientists can publish models (i.e., architectures and weights) and methods. Other scientists can apply existing models to new data with ease (e.g., by querying a prediction API for a deployed model). They can easily create new models with state-of-the-art techniques. Together, these capabilities lower barriers to employing ML/DL, making it easier for researchers to benefit from advances in ML/DL technologies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publishing a Scikit-learn model\n",
    "\n",
    "The example below covers how to publish a scikit-learn model in DLHub. This includes:\n",
    "* Model dataset description ( *The feature to publish dataset description in DLHub is a future work )\n",
    "* Model metadata description\n",
    "* Model publishing\n",
    "\n",
    "As a simple example, we will show how to submit a SVM model created based on the [Iris Dataset](https://archive.ics.uci.edu/ml/datasets/Iris).\n",
    "\n",
    "To publish a model with DLHub we first gather some metadata about the model itself. Our SDK is designed to assist the user in generating this metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing the training dataset\n",
    "\n",
    "The first step is to describe the training data, which we assume is in a csv file named iris.csv in this example.\n",
    "\n",
    "To make the training dataset usable for others, we want to tell them how to read it and what the columns are. Also, to make sure the authors of the data can be properly recognized, we need to provide provenance information. `dlhub_sdk` provides a simple tool for specifying this information: `TabularDataset`.\n",
    "\n",
    "With `TabularDataset` class, the DLHub SDK supports any data **format** readable by the Pandas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlhub_sdk.models.datasets import TabularDataset\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Read in the dataset\n",
    "data = pd.read_csv('scikit_learn_model/iris.csv', header=1)\n",
    "\n",
    "# Make the dataset information\n",
    "dataset_info = TabularDataset.create_model('scikit_learn_model/iris.csv', read_kwargs=dict(header=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can append other metadata to the dataset model, including alternate identifier, paper link, domain and column descriptions, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add link to where this data was downloaded from\n",
    "dataset_info.add_alternate_identifier(identifier=\"https://archive.ics.uci.edu/ml/datasets/Iris\", \n",
    "                                      identifier_type=\"URL\")\n",
    "\n",
    "# Add link to paper describing the dataset\n",
    "dataset_info.add_related_identifier(identifier=\"10.1111/j.1469-1809.1936.tb02137.x\",\n",
    "                                    identifier_type=\"DOI\", \n",
    "                                    relation_type=\"IsDescribedBy\")\n",
    "\n",
    "# Mark the domain of the dataset\n",
    "dataset_info.set_domains([\"biology\"])\n",
    "\n",
    "# Describe the columns\n",
    "dataset_info.annotate_column(\"sepal_length\", description=\"Length of sepal\", units=\"cm\")\n",
    "dataset_info.annotate_column(\"sepal_width\", description=\"Width of sepal\", units=\"cm\")\n",
    "dataset_info.annotate_column(\"petal_length\", description=\"Length of petal\", units=\"cm\")\n",
    "dataset_info.annotate_column(\"petal_width\", description=\"Width of petal\", units=\"cm\")\n",
    "dataset_info.annotate_column(\"species\", description=\"Species\", data_type='string')\n",
    "\n",
    "# Mark which columns are inputs and outputs\n",
    "dataset_info.mark_inputs(data.columns[:-1])\n",
    "dataset_info.mark_labels(data.columns[-1:])\n",
    "\n",
    "# Describe the data provenance\n",
    "dataset_info.set_title(\"Iris Dataset\")\n",
    "dataset_info.set_name(\"iris_dataset\")\n",
    "dataset_info.set_authors([\"Marshall, R.A.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this script, the model produces a simple JSON description of the dataset that we will send to DLHub.\n",
    "Note that the SDK automatically put the metadata in **DataCite** format and includes data automatically pulled from the dataset (e.g., that the inputs are floats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the result\n",
    "print(json.dumps(dataset_info.to_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a model using the Iris dataset\n",
    "\n",
    "Now we create a simple SVM model using scikit-learn based on the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('scikit_learn_model/iris.csv', header=1)\n",
    "print('Loaded {} rows with {} columns:'.format(len(data), len(data.columns)),\n",
    "      data.columns.tolist())\n",
    "\n",
    "# Make the model\n",
    "model = SVC(kernel='linear', C=1, probability=True)\n",
    "model.fit(data.values[:, :-1], data.values[:, -1])\n",
    "print('Trained a SVC model')\n",
    "\n",
    "# Save the model using pickle\n",
    "with open('scikit_learn_model/model.pkl', 'wb') as fp:\n",
    "    pkl.dump(model, fp)\n",
    "print('Saved model to disk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the model\n",
    "\n",
    "For brevity, we will upload much less metadata about a model created using Scikit-Learn.\n",
    "\n",
    "We simply load in a Scikit-Learn model from a pickle file, and then provide a minimal amount of information about it.\n",
    "\n",
    "The SDK will inspect the pickle file to determine the type of the model and the version of scikit-learn that was used to create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlhub_sdk.models.servables.sklearn import ScikitLearnModel\n",
    "\n",
    "model_info = ScikitLearnModel.create_model('scikit_learn_model/model.pkl', n_input_columns=len(data.columns) - 1,\n",
    "                                           classes=data['species'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the SDK to append other metadata to the model. Below we set the name, title and domain of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Describe the model\n",
    "model_info.set_title(\"Example Scikit-Learn Model\")\n",
    "model_info.set_name(\"iris_svm\")\n",
    "model_info.set_domains([\"biology\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the metadata is created we can use it to publish the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(model_info.to_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publishing the model to DLHub\n",
    "\n",
    "We can use the DLHub SDK to create a DLHubClient. The DLHubClient wraps both our REST API and Search catalog. You can use the client to publish, discover, and use models.\n",
    "\n",
    "This may take ~10 minutes to publish the model to DLHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlhub_sdk\n",
    "dl = dlhub_sdk.DLHubClient()\n",
    "\n",
    "# Publish the model to DLHub\n",
    "task_id = dl.publish_servable(model_info)\n",
    "print(task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dask]",
   "language": "python",
   "name": "conda-env-dask-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
