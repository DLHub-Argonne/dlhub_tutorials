{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DLHub: A Data and Learning Hub for Science\n",
    "\n",
    "DLHub is a self-service platform for publishing, applying, and creating machine learning (ML) models, including deep learning (DL) models, and associated data transformations. It is:\n",
    "\n",
    "1. A **model serving infrastructure**: Users can easily run or test models (and also other related services, such as data transformations) via simple Web calls.\n",
    "\n",
    "2. A **model registry**: Model developers can easily publish models, along with associated descriptive metadata and training data, so that they can then be discovered, cited, and reused by others.\n",
    "\n",
    "3. A **model development system**: Developers of new models can easily access the data and computing infrastructure needed to re-train models for new applications.\n",
    "\n",
    "DLHub benefits users in many ways. Data scientists can publish models (i.e., architectures and weights) and methods. Other scientists can apply existing models to new data with ease (e.g., by querying a prediction API for a deployed model). They can easily create new models with state-of-the-art techniques. Together, these capabilities lower barriers to employing ML/DL, making it easier for researchers to benefit from advances in ML/DL technologies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publishing a Keras model\n",
    "\n",
    "The example below covers how to publish a Keras model in DLHub. This includes:\n",
    "* Model dataset description ( *The feature to publish dataset description in DLHub is a future work )\n",
    "* Model metadata description\n",
    "* Model publishing\n",
    "\n",
    "As a simple example, we will show how to submit a Keras model based on the [MNIST database](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "To publish a model with DLHub we first gather some metadata about the model itself. Our SDK is designed to assist the user in generating this metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a model using the MNIST dataset\n",
    "\n",
    "Now we create a simple convnet on the MNIST dataset.\n",
    "\n",
    "This model is taken from: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "\n",
    "Modified to:\n",
    "    - Use only 1024 examples for faster training\n",
    "    - Save model to hd5 at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-db530afa1387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 4\n",
    "train_size = 512\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train[:train_size], y_train[:train_size],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Save the model\n",
    "model.save(\"MNIST_model/model.hd5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the model\n",
    "\n",
    "For brevity, we will upload much less metadata about a model created using Scikit-Learn.\n",
    "\n",
    "We simply load in a Scikit-Learn model from a pickle file, and then provide a minimal amount of information about it.\n",
    "\n",
    "The SDK will inspect the pickle file to determine the type of the model and the version of scikit-learn that was used to create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlhub_sdk.models.servables.sklearn import ScikitLearnModel\n",
    "\n",
    "model_info = ScikitLearnModel.create_model('scikit_learn_model/model.pkl', n_input_columns=len(data.columns) - 1,\n",
    "                                           classes=data['species'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the SDK to append other metadata to the model. Below we set the name, title and domain of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dlhub_sdk.models.servables.sklearn.ScikitLearnModel at 0x7f310ef1e630>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#    Describe the model\n",
    "model_info.set_title(\"Example Scikit-Learn Model\")\n",
    "model_info.set_name(\"iris_svm\")\n",
    "model_info.set_domains([\"biology\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the metadata is created we can use it to publish the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datacite\": {\n",
      "    \"creators\": [],\n",
      "    \"titles\": [\n",
      "      {\n",
      "        \"title\": \"Example Scikit-Learn Model\"\n",
      "      }\n",
      "    ],\n",
      "    \"publisher\": \"DLHub\",\n",
      "    \"publicationYear\": \"2019\",\n",
      "    \"identifier\": {\n",
      "      \"identifier\": \"10.YET/UNASSIGNED\",\n",
      "      \"identifierType\": \"DOI\"\n",
      "    },\n",
      "    \"descriptions\": [],\n",
      "    \"fundingReferences\": [],\n",
      "    \"relatedIdentifiers\": [],\n",
      "    \"alternateIdentifiers\": [],\n",
      "    \"rightsList\": [],\n",
      "    \"resourceType\": {\n",
      "      \"resourceTypeGeneral\": \"InteractiveResource\"\n",
      "    }\n",
      "  },\n",
      "  \"dlhub\": {\n",
      "    \"version\": \"0.7.2\",\n",
      "    \"domains\": [\n",
      "      \"biology\"\n",
      "    ],\n",
      "    \"visible_to\": [\n",
      "      \"public\"\n",
      "    ],\n",
      "    \"name\": \"iris_svm\",\n",
      "    \"files\": {\n",
      "      \"model\": \"scikit_learn_model/model.pkl\"\n",
      "    },\n",
      "    \"type\": \"servable\"\n",
      "  },\n",
      "  \"servable\": {\n",
      "    \"methods\": {\n",
      "      \"run\": {\n",
      "        \"input\": {\n",
      "          \"type\": \"ndarray\",\n",
      "          \"description\": \"List of records to evaluate with model. Each record is a list of 4 variables.\",\n",
      "          \"shape\": [\n",
      "            null,\n",
      "            4\n",
      "          ],\n",
      "          \"item_type\": {\n",
      "            \"type\": \"float\"\n",
      "          }\n",
      "        },\n",
      "        \"output\": {\n",
      "          \"type\": \"ndarray\",\n",
      "          \"description\": \"Probabilities for membership in each of 3 classes\",\n",
      "          \"shape\": [\n",
      "            null,\n",
      "            3\n",
      "          ],\n",
      "          \"item_type\": {\n",
      "            \"type\": \"float\"\n",
      "          }\n",
      "        },\n",
      "        \"parameters\": {},\n",
      "        \"method_details\": {\n",
      "          \"method_name\": \"_predict_proba\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"shim\": \"sklearn.ScikitLearnServable\",\n",
      "    \"type\": \"Scikit-learn estimator\",\n",
      "    \"dependencies\": {\n",
      "      \"python\": {\n",
      "        \"scikit-learn\": \"0.20.3\"\n",
      "      }\n",
      "    },\n",
      "    \"language\": \"python\",\n",
      "    \"options\": {\n",
      "      \"serialization_method\": \"pickle\",\n",
      "      \"classes\": [\n",
      "        \"setosa\",\n",
      "        \"versicolor\",\n",
      "        \"virginica\"\n",
      "      ],\n",
      "      \"is_classifier\": true\n",
      "    },\n",
      "    \"model_type\": \"SVC\",\n",
      "    \"model_summary\": \"SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\\n  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\\n  kernel='linear', max_iter=-1, probability=True, random_state=None,\\n  shrinking=True, tol=0.001, verbose=False)\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(model_info.to_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publishing the model to DLHub\n",
    "\n",
    "We can use the DLHub SDK to create a DLHubClient. The DLHubClient wraps both our REST API and Search catalog. You can use the client to publish, discover, and use models.\n",
    "\n",
    "This may take ~10 minutes to publish the model to DLHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2493b2d8-42c2-4745-94a9-53acc7c61492\n"
     ]
    }
   ],
   "source": [
    "import dlhub_sdk\n",
    "dl = dlhub_sdk.DLHubClient()\n",
    "\n",
    "# Publish the model to DLHub\n",
    "task_id = dl.publish_servable(model_info)\n",
    "print(task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
